h2. Getting Started with Ubuntu

[TODO: aptitude instead of apt-get, is aptitude update the same as apt-get update?]

This guide covers how to set up a new Ubuntu 10.10 in a manual fashion for a single application and provides the basics for hosting a Rails application.

You will need sudo access on the server to set up some things in this guide.

* Set up an application's user
* Install RVM 
* Install Ruby 1.9.2

This guide assumes that a version of Ubuntu (10.10 or greater) is installed on an accessible server.

The guide sets up a +deploy+ user which has an RVM install which contains Ruby 1.9.2. This user's folder will also include the application which we're wishing to deploy and this folder will be set up to be owned by the +deploy+ user. The user does not have to be called +deploy+, it is used only as an example throughout this guide.

endprologue.

h3. First things first

NOTE: This guide assumes you have installed OpenSSH or some form of SSH to connect to this server and it's currently running on port 22. This is a requirement for doing deploys to this server.

WARNING: Under no circumstance should you log into a server as root. Use the personal account that was set up when the operating system was installed and +sudo+ when necessary.

The majority of software packages are installed on Ubuntu using a system called Aptitude. We can also install packages from source if we wish (with the help of a package called +build_essential+ which contains the build tools we need). These Aptitude packages are downloaded from a source repository and then installed for us. To ensure that these sources are up-to-date we can run this command:

<pre>
  sudo apt-get update
</pre>

This command goes through the list of sources, connecting to each of them and downloads a package list which is then cached by Ubuntu. When we go to install a package (our next step), Ubuntu will reference these lists to find the packages and the necessary dependencies for them.

Once this update command is complete then we're free to go about setting up this server using these packages, beginning with setting up a user with RVM. To use RVM we're going to need a couple of packages, so we'll install these first:

<pre>
  sudo apt-get install build-essential git-core curl
</pre>

The +build_essential+ package includes the required components for building code, such as the C code contained within Ruby. The +git-core+ package provides the base of the Git version control system, allowing us to use Git commands when we need them. The final package, +curl+ is required for the install of RVM, as we'll use it to download the script used to setup RVM. This package can be used to connect to a URL and stream its data into a file.

Before we do that however we'll need to set up a user which will act as the owner of our deployed application.

h3. Setting up a user

The first thing we're going to need for our new server is a user which owns the application. Many people call this user +deploy+, but it's name isn't important. The function of this user is, however. This user account will be limited to operating only on things inside of its home directory (+/home/deploy+) and will not be able to run any commands as root.

h4. Adding the user 

To set up this user we'll use this command:

<pre>
  sudo useradd deploy -s /bin/bash -d /home/deploy
  sudo mkdir /home/deploy
  sudo chown -R deploy /home/deploy
  sudo passwd deploy
</pre>

On the first line we've used a couple of options to the +useradd+ command. The +-s+ option sets the shell for the user to +/bin/bash+ and the +-d+ option sets their home directory to +/home/deploy+. The next command, +mkdir+ (read as "make dir"), creates this home directory while the third command, +chown+ ("change owner") changes the owner of the directory to be the +deploy+ user. The final command +passwd+ prompts us to set a password for this user, which we should set to something complex to stop people hacking our deploy user.

In the next step, we'll set up a key which will allow us to login as our user and +deploy+ on our server without a password. This is called key-based authentication and requires two files, a private key and a public key. The private key goes on the developer's computer and should be kept private, as the name implies, as it is the key to gain access to the server. The public key file can be shared with anybody and is used by a server to authenticate a user's private key. The content of these files is different and the OpenSSH package takes care of comparing them. If these match up, then a user is granted access to the server.

[TODO: Add image describing this process]

We're going to be using a key-based authentication for our server because it is incredibly secure versus a password authentication scheme. To quote the official Ubuntu instructions on this (https://help.ubuntu.com/community/SSH/OpenSSH/Configuring):

    "To be as hard to guess as a normal SSH key, a password would have to contain 634 random letters and numbers"

Considering the average password length is 8 characters, this an exceptionally vast improvement over password-based authentication. After we enable this key-based login for our two current users, we'll be disabling password authentication. This limits the number of computers which can access this server to just those with the private key file.

To set up our user correctly we'll need to create the +~/.ssh+ directory for our user using this command:

<pre>
  mkdir ~/.ssh
</pre>

Then we'll need to do the same for the +deploy+ user. The difference is that this directory needs to be owned by this user and so the easiest way to do that would be to switch to the user and create it through that account.

<pre>
  sudo su deploy
  mkdir ~/.ssh
</pre>

h4. Setting a key

The +su+ command is the way that we can use to switch to this user on this machine, but to deploy to this user we will need some way of remotely accessing the machine. On our local machine we may have already generated a private key (usually +~/.ssh/id_rsa+ or +id_dsa+) which has a related file with the same name, but with a +pub+ extension. 

If we don't have one of these we can generate a new one using the +ssh-keygen -t rsa+ command, entering no passphrase for the key so that we're not prompted to enter it every time it's accessed. This generates a new public and private key at +~/.ssh/id_rsa.pub+ and +~/.ssh/id_rsa+ respectively, assuming that the defaults were left unaltered.

We can copy the public key to the server for the +deploy+ and our user, by using the +scp+ command from our local box.:

<pre>
  scp ~/.ssh/id_rsa.pub deploy@server:~/.ssh/authorized_keys
  scp ~/.ssh/id_rsa.pub ryan@server:~/.ssh/authorized_keys
</pre>

We'll need to enter the same password here as when we set up the users so that the key is copied over in both situations. The second line in the above example contains the username "ryan" and chances are your first user is called differently. Remember to change this to your user.

The destination filename, +~/.ssh/authorized_keys+, is important here as SSH will check this file for a list of keys that are authorized for this user. If a user's private key matches up with the public key on the server then they will be granted access, without having to use a password. Each private key is unique, and so this is a pretty secure method. 

h4. Disabling password authentication

Now's a great time to make sure that the log in to the server is working for both of these accounts with the key-based authentication, because we're about to turn off the password authentication method to make our server much more secure. From outside of the server, attempt to ssh to it:

<pre>
  ssh deploy@server
</pre>

We should not be prompted to enter a password, if we are then something's gone Terribly, Terribly Wrong (TTW). Go back over the instructions here to see if a spot's been missed.

If everything's working with the keys then it's safe to turn off password authentication in our SSH configuration. To do this we'll open +/etc/ssh/sshd_config+ using +nano /etc/ssh/sshd_config+ and add +PasswordAuthentication no+ to where it would otherwise say +#PasswordAuthentication yes+ (the +#+ indicates a commented line, just like Ruby), exiting out by pressing Ctrl\+X and then Y. We need to reload this configuration for the changes to take effect and the easiest way to do that would be to restart SSH, which can be done with this command:

<pre>
  sudo /etc/init.d/ssh restart
</pre>

Now our server is only accessible by users which have the public key added to the lists, making it exceptionally more secure than simple password authentication would allow.

With the majority of our server set up now, it's time to install Ruby on this server.

h3. Installing RVM

Now we could install Ruby by downloading the package manually, un-gzip'ing it and un-tar'ing it, but that's boring. Wouldn't it be nice if there was a tool that would do it for us?

There is! It's called +rvm+!

RVM gives us several benefits over a standard Ruby compile, such as being able to install and upgrade our Ruby install very easily. No digging for links on the +ruby-lang.org+ site for us, no siree.

There's a couple of ways we can install RVM. The first is a user-based install, installing it in a +.rvm+ directory within the user's home directory. This would make RVM available for a single user which is what we're after, as we want to make it available for the +deploy+ user.

But then if we wish to install anything that requires +sudo+ privileges (such as anything that would modify our system's files by running a command, like the commonly-used Passenger gem) then we would need it accessible for users who aren't the +deploy+ user, such as our own personal account used to administer the server. 

Therefore we'll install RVM at a system level, which we can do by getting out of the +deploy+ user and back up to our root-privileges user by typing +exit+ and then running this command:

<pre>
 sudo bash < <( curl -L http://bit.ly/rvm-install-system-wide )
</pre>

Once this script has finished executing we should see a lot of output, and part of it will contain installation instructions for packages we need to install before we install Ruby. The installation advises to run this command if we're wanting to install MRI (Matz's Ruby Interpreter) or ree versions of Ruby, which we are!

<pre>
  sudo aptitude install build-essential bison openssl libreadline6 libreadline6-dev curl git-core zlib1g zlib1g-dev libssl-dev libyaml-dev libsqlite3-0 libsqlite3-dev sqlite3 libxml2-dev libxslt-dev autoconf libc6-dev
</pre>

The next step is making sure that the RVM directories are owned by the +root+ user and the +rvm+ group which we should create now and make ourselves a part of by using this:

<pre>
    sudo groupadd rvm
    sudo usermod -g rvm
</pre>

With this group added and ourselves a part of it, we can switch the ownership of the rvm directories and files to be owned by the +root+ user and the +rvm+ group:

<pre>
  sudo chown -R root:rvm /usr/local/rvm /usr/local/bin /etc/rvmrc
</pre>

This will allow us to install gems using +gem install+, such as Bundler and Rails, while leaving the gems in a read-only state for other users. 

We'll now need to add the RVM script to +/etc/profile+ so that when new terminal sessions are launched for any user the +rvm+ command will be available, allowing us to install Ruby. We'll use the +root+ user temporarily to do this:

<pre>
  sudo su
  echo 'source "/usr/local/rvm/scripts/rvm"' >> /etc/profile
  exit
</pre>

With RVM installed and its script setup we can proceed to installing the version of Ruby we need: 1.9.2.

h3. Installing Ruby

1.9.2-p136 is the latest version of MRI (Matz's Ruby Interpreter) which has been released and is considered stable. To install this version of Ruby we can run this command:

<pre>
  rvm install 1.9.2
</pre>

This will install 1.9.2-p136 which is the latest stable release of Ruby 1.9.2 and is perfect for this environment.

Right now to begin to use this Ruby we can run:

<pre>
  rvm use 1.9.2
</pre>

A better idea would be to make this the default Ruby for this user, so that whenever we're logged in as a user we'll have access to the RVM-provided Ruby. Running this command will set that default:

<pre>
  rvm use --default 1.9.2
</pre>

Next, we'll need to install the +rails+ and +bundler+ gems as these are the staples of getting our application to work:

<pre>
  gem install rails bundler
</pre>

Of course we need the +rails+ gem to run our Rails application, and because we're using Rails 3 and it uses Bundler, we'll obviously need the +bundler+ gem.

So now we've got a pretty good environment set up for our application, but we don't have our application on the server yet. We can put it there with another gem called Capistrano.

h3. Capistrano

Capistrano is a gem originally created by Jamis Buck but is now maintained by Lee Hambley and additional volunteers. It is designed for easy application deployment, not limited to Rails.

In this guide, we'll be using the Ticketee application from <a href='http://manning.com/katz'>Rails 3 in Action</a> as an example, which can be found at http://github.com/rails3book/ticketee.

The majority of this guide is also covered in the official Capistrano guide, which may provide some additional insight. https://github.com/capistrano/capistrano/wiki/2.x-From-The-Beginning. This guide provides a concise walkthrough of every command that we'll use to set up a server.

Capistrano provides an easy way to configure and deploy versions of an application to one or many servers. Capistrano also allows us to roll back to a previous version of the application if we wish.

h4. Installation and setup

The +capistrano+ gem must be installed on all computers which will be used to deploy the application, but _not_ the servers where the applications are deployed to. To install this gem we will run this command:

<pre>
  gem install capistrano
</pre>

When the gem is installed we can set it up inside a Rails application by running this command from the root of the application:

<pre>
  capify
</pre>

This will create two files: +Capfile+ and +config/deploy.rb+. The +Capfile+ is a file containing set up for Capistrano in the application and contains this code:

<pre>
  load 'deploy' if respond_to?(:namespace) # cap2 differentiator
  Dir['vendor/plugins/*/recipes/*.rb'].each { |plugin| load(plugin) }

  load 'config/deploy' # remove this line to skip loading any of the default tasks
</pre>

The second line here will load any files of any plugins that are in that plugin's recipes directory. We'll look at recipes later on in this guide, in the "Recipes" section.

The +config/deploy.rb+ file contains the configuration for deploying our application and begins with these two lines:

<ruby>
  set :application, "set your application name here"
  set :repository,  "set your repository location here"
</ruby>

When we call +set+ in Capistrano it sets a variable we (or Capistrano itself) can reference later. The +application+ variable here should be the name of our application and the +repository+ variable should be the path to our application. Let's change these lines to this:

<ruby>
  set :application, "ticketee"
  set :repository,  "git://github.com/rails3book/ticketee.git"
</ruby>

Underneath this repository line we'll configure Capistrano to pull from the +production+ branch instead of the default (the +master+ branch for Git):

<ruby>
  set :branch, "production"
</ruby>

For the reasons on this see the "Branching" section of the "Getting Started" guide.

On the next line there's the +scm+ setting:

<ruby>
  set :scm, :subversion
</ruby>

We're going to be using Git and not Subversion in this case, so we'll change this line to this:

<ruby>
  set :scm, :git
</ruby>

On the next few lines there are a couple of roles defined. These roles point to:

* +web+: The server or servers which are responsible for serving requests for our application
* +app+: The server or servers where the application's code is hosted.
* +db+: The server or servers where the database for the application is hosted.

Right now we won't worry about multiple server setups, focussing only on having everything on the one box. The "your *-server here" lines will be replaced with the IP or FQDN (Fully-Qualified Domain Name), something that looks like this:

<ruby>
  role :web, "192.168.137.130"
  role :app, "192.168.137.130"
  role :db,  "192.168.137.130", :primary => true
</ruby>

Two more settings that we'll need to set up is the user and the path where we're going to deploy our application to. The user will be the +deploy+ user and the path will be +/home/deploy/apps+, with the application name being used as the name of a sub-folder of that application. Underneath the +set :scm+ line we will put this:

<ruby>
  set :user, "deploy"
  set :deploy_to, "/home/deploy/apps/#{application}"
</ruby>

We'll also tell Capistrano not to use the +sudo+ command, given that everything should now be installable by this user:

<ruby>
  set :use_sudo, false
</ruby>

Lastly, at the bottom of the file there are a couple of lines for defining +deploy:start+, +deploy:stop+ and +deploy:restart+ tasks for Passenger which are commented out. Let's remove the comment hash from the beginning of these lines, transforming them to this:

<ruby>
  namespace :deploy do
    task :start do ; end
    task :stop do ; end
    task :restart, :roles => :app, :except => { :no_release => true } do
      run "#{try_sudo} touch #{File.join(current_path,'tmp','restart.txt')}"
    end
  end
</ruby>

This will override Capistrano's default +deploy:start+ and +deploy:stop+ tasks to do nothing, and the +deploy:restart+ task to touch a file at +current_path+ (+/home/deploy/apps/ticketee/current+) in the +tmp+ folder called +restart.txt+. When this file has been touched, Passenger will restart the application abandoning the old code and loading the newly deployed code upon the next request.

With the Capistrano configuration done, we can run the +cap+ command, passing in the name of a task to set up our application, such as +deploy:setup+. This task is one of a group of tasks that are provided by default with Capistrano. To see a list of these tasks we can use the +cap -T+ command.

We'll now use the +deploy:setup+ task which will set up the folder where our application is deployed, +/home/deploy/apps/ticketee+, with some basic folders:

<pre>
  cap deploy:setup
</pre>

This command is in the same vein as the +rails new+ command we've used previously, as it sets up an identical, standard scaffold for every Capistrano. When this command runs, we'll see a large chunk of output which we'll now break down, one line at a time:

<pre>
  * executing `deploy:setup'
</pre>

Capistrano tells us the name of the currently executing task, +deploy:setup+. The next line tells us what command it is about to execute.

<pre>
    * executing "mkdir -p /home/deploy/apps/ticketee
                          /home/deploy/apps/ticketee/releases 
                          /home/deploy/apps/ticketee/shared 
                          /home/deploy/apps/ticketee/shared/system
                          /home/deploy/apps/ticketee/shared/log
                          /home/deploy/apps/ticketee/shared/pids
</pre>

The basic directories required for Capistrano. The first directory acts as a base for our application, containing several different sub directories, the first of which being +releases+. 

Whenever we deploy using Capistrano, a new release is created in the +releases+ directory, timestamped to the current time using the same time format as migrations within Rails (e.g. 20110205225746, or YYYYMMDDHHmmSS). The latest release of course would be the final one in this directory.

The +shared+ directory is the directory where files can be shared across releases, such as uploads that would usually go in the +public/system+ directory, which would now be placed in +shared/system+. 

(Perhaps explain "symbolically linked")

The +shared/log+ directory is symbolically linked to the current release's +log+ directory when we run a deploy. This is so that all logs will be kept in the +shared/log+ directory, rather than in each release.

The +shared/pids+ directory is symbolically linked to the current release's +tmp/pids+ up on deploy. This folder is used for ...

The next line after this makes these folders group writable with the +chmod+ command:

<pre>
  chmod g+w /home/deploy/apps/ticketee
            /home/deploy/apps/ticketee/releases
            /home/deploy/apps/ticketee/shared
            /home/deploy/apps/ticketee/shared/system 
            /home/deploy/apps/ticketee/shared/log
            /home/deploy/apps/ticketee/shared/pids"
</pre>

At the bottom of this command's output we can see what servers it will be executed on, with just the one server for now. It also tells us that the command is being executed and, faster than we can blink, that the command has finished.

<pre>
  servers: ["192.168.137.130"]
  [192.168.137.130] executing command
  command finished
</pre>

Once the +deploy:setup+ Capistrano task has finished then +cap deploy:setup+ also finishes, returning us to the console. Now we can deploy our application!

h3. Deploy!

Capistrano has now been configured to deploy the Ticketee application and we've set up our server using the +cap deploy:setup+ command, leaving it up to us now to deploy our code. Capistrano's +deploy+ task will let us do this, and we can run this task with this command:

<pre>
  cap deploy
</pre>

This command outputs an even larger output to +cap deploy:setup+, but again we'll go through it line by line. It's not really all that intimidating when its broken down into little chunks, really!

h5. In the beginning (of a deploy)

The first output we'll see from a deploy is:

<pre>
 * executing `deploy'
 * executing `deploy:update'
 ** transaction: start
 * executing `deploy:update_code'
</pre>

These first three lines tell us the tasks which are being executed. Of course the +deploy+ task is going to be executed because we asked Capistrano to do that. This task depends on the +deploy:update+ task, and so it will run that. 

The +deploy:update+ task begins a transaction (the third line here), which is exceptionally helpful. If anything goes wrong in our deploy, Capistrano will rollback everything to the beginning of this transaction, deleting any code it's deployed. This transaction's a failsafe for our deploy.

Finally from this part of the output is the +deploy:update_code+ task, which is responsible for updating the application's code in our deployment environment. This task is responsible for this code:

<pre>
  executing locally: "git ls-remote git://github.com/rails3book/ticketee production"
  * executing "git clone -q git://github.com/rails3book/ticketee /home/deploy/apps/ticketee/releases/20110206070736 && cd /home/deploy/apps/ticketee/releases/20110206070736 && git checkout -q -b deploy c4517c264d2d92b1cb179f9d4fe47a985c69745a && (echo c4517c264d2d92b1cb179f9d4fe47a985c69745a > /home/deploy/apps/ticketee/releases/20110206070736/REVISION)"
      servers: ["192.168.137.130"]
      [192.168.137.130] executing command
      command finished
</pre>

 This task first runs +git ls-remote+, a lesser known Git command, locally (not on the server) which will get the current SHA for the +production+ branch, which at the moment is +c4517c264d2d92b1cb179f9d4fe47a985c69745a+. 

The +deploy:update_code+ then clones the repository using +git clone+ into a new release directory, with the timestamp (20110206070736). Then it checks out the revision to a new branch called +deploy+.

The next thing Capistrano does is it puts the current revision in a file called +REVISION+. If we like, we could alter the layout of our application read the value from this file and put it in our application's layout as a HTML comment so that when we do a deploy to the server, we can check this hash to see if it is the latest code.

That's the end of +deploy:update_code+. The next couple of lines are from the beginning of the +deploy:finalize_update+:


<pre>
 * executing `deploy:finalize_update'
 * executing "chmod -R g+w /home/deploy/apps/ticketee/releases/20110206033659"
   servers: ["192.168.137.130"]
   [192.168.137.130] executing command
   command finished
</pre>

With this +chmod+ command, Capistrano ensures that our new release's directory is group writable (+g\+w+), allowing the user / group to make any modifications to this directory they like.

Finally, the +deploy:finalize_update+ then removes the +log+, +public/system+ and +tmp/pids+ directories and symbolically links the +shared/log+, +shared/system+ and +shared/pids+ directories (in our application's deployed path) to these paths respectively. It does that in this little command:

<pre>
   * executing "rm -rf /home/deploy/apps/ticketee/releases/20110206033659/log /home/deploy/apps/ticketee/releases/20110206033659/public/system /home/deploy/apps/ticketee/releases/20110206033659/tmp/pids &&\\\n      mkdir -p /home/deploy/apps/ticketee/releases/20110206033659/public &&\\\n      mkdir -p /home/deploy/apps/ticketee/releases/20110206033659/tmp &&\\\n      ln -s /home/deploy/apps/ticketee/shared/log /home/deploy/apps/ticketee/releases/20110206033659/log &&\\\n      ln -s /home/deploy/apps/ticketee/shared/system /home/deploy/apps/ticketee/releases/20110206033659/public/system &&\\\n      ln -s /home/deploy/apps/ticketee/shared/pids /home/deploy/apps/ticketee/releases/20110206033659/tmp/pids"
     servers: ["192.168.137.130"]
     [192.168.137.130] executing command
     command finished
</pre>

Next, Capistrano will use the +find+ command to +touch+ every file in the +public/images+, +public/stylesheets+ and +public/javascripts+ to update their last modified time. This is so that when a user visits our site they get the latest image, stylesheet or javascript file rather than a cached file. It does this with this part of the output:

<pre>
 * executing "find /home/deploy/apps/ticketee/releases/20110206033659/public/images /home/deploy/apps/ticketee/releases/20110206033659/public/stylesheets /home/deploy/apps/ticketee/releases/20110206033659/public/javascripts -exec touch -t 201102060337.13 {} ';'; true"
   servers: ["192.168.137.130"]
   [192.168.137.130] executing command
   command finished
</pre>

The final step for the +deploy:update_code+ task is to run the +deploy:symlink+ task which symbolically links the new release directory to the +current+ folder within our deploy path (in this example, +/home/deploy/apps/ticketee/current+).

<pre>
 * executing `deploy:symlink'
 * executing "rm -f /home/deploy/apps/ticketee/current && ln -s /home/deploy/apps/ticketee/releases/20110206033659 /home/deploy/apps/ticketee/current"
   servers: ["192.168.137.130"]
   [192.168.137.130] executing command
   command finished
</pre>

The final action of the +deploy:update+ task is to commit the transaction that began at the start, meaning our deploy was successful:

<pre>
  ** transaction: commit
</pre>

The absolutely final thing the +deploy+ task does is call +deploy:restart+ which will touch the +tmp/restart+ file in our new application directory (+/home/deploy/apps/ticketee/current+):

<pre>
 * executing `deploy:restart'
 * executing "touch /home/deploy/apps/ticketee/current/tmp/restart.txt"
   servers: ["192.168.137.130"]
   [192.168.137.130] executing command
   command finished
</pre>

And that's it! Our application is deployed for the first time, however it's not quite ready yet for prime-time usage. For starters, the application's gems are most certainly not installed. On our development box we would do this by running the +bundle install+ task, which is actually provided to us by file that comes with Bundler.

h5. Bundler

We can trigger the +bundle install+ task to happen when we do a deploy by requiring the +bundler/capistrano+ file in the +config/deploy+ of our application, right at the very top:

<ruby>
  require 'bundler/capistrano'
</ruby>

We'll also need to require RVM's +capistrano+ configuration so that when we do a deploy it can locate the +bundle+ command (provided by RVM) which it will need to run +bundle install+. At the top of +config/deploy.rb+ we'll put this line also:

<ruby>
  require 'rvm/capistrano'
</ruby>

When we run +cap deploy+ again, we'll see this additional output, just after the stylesheets, javascripts and images touching:

<pre>
  * executing `bundle:install'
  * executing "ls -x /home/deploy/apps/ticketee/releases"
    servers: ["192.168.137.130"]
    [192.168.137.130] executing command
    command finished
  * executing "bundle install --gemfile /home/deploy/apps/ticketee/releases/20110207202618/Gemfile --path /home/deploy/apps/ticketee/shared/bundle --deployment --quiet --without development test"
    servers: ["192.168.137.130"]
    [192.168.137.130] executing command
    command finished
</pre>

Bundler's added a +bundle:install+ task to our Capistrano configuration which runs after +deploy:finalize_update+. This task runs +ls -x+ command at the beginning to get the last release's directory (+20110207202618+, in this case), which it then uses to specify the location of the +Gemfile+ using the +--gemfile+ flag passed to +bundle install+.

Rather than installing the gems to a system location which may not be writable by this user (our +/usr/local/rvm+ directories certainly aren't), Bundler elects instead to install this to the +/home/deploy/apps/ticketee/shared/bundler+ directory instead, specified by the +--path+ flag. 

The +--deployment+ flag specifies that the repository must contain a +Gemfile.lock+ file (meaning the gem versions are locked) and that the +Gemfile.lock+ file is up-to-date according to the +Gemfile+. This is to ensure that we're running an identical gemset on our server and local machines.

Lastly, the +--without+ flag tells Bundler what groups to ignore. The +development+ and +test+ groups are ignored in this case, meaning gems specified in these two groups will not be installed.

With our application's gems installed we're getting even closer to having an application running. When we deploy changes to our application these changes may include new migrations which will need to be run on the server after we do a deploy. We can deploy our code _and_ migrate by running this lovely command:

<text>
  cap deploy:migrations
</text>

When the command runs we'll see that the migrations for our application have run. Ideally, we should use this command to always do a deploy to ensure that all the migrations are up to date, rather than +cap deploy+, which wouldn't.

With our application's code on the server and the migrations run, we still don't have a way of receiving requests. To set that up, we'll be using the Passenger gem.

h3. Passenger

Passenger is a gem which provides a module for either the Apache or nginx web-servers which allows for Rack-based applications (including Rails applications) to be hosted using these services.

Passenger allows us to run multiple instances of the application (as opposed to a +rails server+ launch, which is simply one), allowing us to serve a large number of requests at any particular point in time. In addition to this, Passenger is highly configurable but also incredibly easy to set up.

When we run +rails server+ it launches a Ruby server called WEBrick which is then responsible for serving every request for the application, including assets. This server is fine for testing but shouldn't be used under any sort of load.

A web server such as Apache or nginx is _designed_ to be used under load, to share static assets, such as stylesheets, javascript files or images, and so this makes these servers much faster than Ruby's WEBrick by an extraordinary amount.

The Passenger gem provides a module for either Apache or Nginx which acts as a bridge between these servers and our Rails application, handling things such as starting up new instances of the application when the load spikes and culling them when the load isn't so high. As stated before, Passenger is really configurable and we'll see some examples here.

h4. Installing Passenger

To install the Passenger gem we will use the +gem install+ command as our user on the server:

<pre>
  gem install passenger
</pre>

With the gem installed, we can now install the module for either Apache _or_ nginx on our system, but before that we'll need to install one of these two servers. Rather than favouring one over the other, the next two sections go into how to install each of them.

NOTE: You only need to install Apache **or** nginx, not both.

h4. Apache

Apache is a very popular webserver provided by the Apache Web Foundation. The majority of websites (about 66%) in the world are powered by it.

h5. Installation & Configuration

To install Apache we'll run this command:

<pre>
  sudo apt-get install apache2
</pre>

We can see if this has been installed by going to http://our-server. We should see the following page:

[Show image of default apache page]

Next, we need to install the Passenger module for this server which is possible through a command provided by the Passenger gem itself:

<pre>
  passenger-install-apache2-module
</pre>

When we run this command we're told that a couple of things are missing:

[TODO: place image here of missing packages]

If we press enter again we're told how to install these packages. These packages are: +libcurl4-openssl-dev+, +apache2-prefork-dev+, +libapr1-dev+ and +libaprutil1-dev+. To install them we'll run this:

<pre>
  sudo apt-get install libcurl4-openssl-dev apache2-prefork-dev libapr1-dev libaprutil1-dev
</pre>

Once this command has finished running we will have the necessary packages to install the Passenger Apache module. Let's run +passenger-install-apache2-module+ again. Give it a minute or two to install. At the end, we'll see these instructions:

[TODO: Apache module install instructions]

Copy these instructions into the clipboard and save them. Then press enter to complete the installation.

We need to add these +LoadModule+ instructions into our Apache configuration so that the Passenger module which we just installed will be used. Apache has the configuration for several modules already in the +/etc/apache2/mods-available+ directory which is just perfect for what we need. Each file in this directory contains configuration only for one module within Apache, allowing us to view just that configuration without it being thrown in with the rest. 

We'll create a new file in this directory by using the +nano /etc/apache2/mods-available/passenger.load+ command. Inside this file we'll put the configuration for loading the module. To enable this configuration we need to use the +a2enmod+ command like this:

<pre>
  sudo a2enmod passenger
</pre>

This command symbolically links this file into +/etc/apache2/mods-enabled+. We're then prompted to restart Apache, which we can do with +sudo /etc/init.d/apache2 restart+.

At the bottom of the Passenger output there's more instructions, this time on how to deploy our application using a +VirtualHost+ block in Apache [TODO: Explain what a VirtualHost in Apache is]

[TODO: Apache virtual host install instructions]

These instructions at the bottom of the output here tell us what we need to put into our Apache configuration to get this to run our application. Apache comes with a default file containing a +VirtualHost+ block, which just displays the welcome page we saw earlier. We're going to overwrite this file with our application's +VirtualHost+ configuration. We'll run +sudo nano /etc/apache2/sites-enabled/000-default+ and then delete every line in this file, replacing it with the following:

<pre>
  <VirtualHost *:80>
     ServerName our-server
     DocumentRoot /home/deploy/apps/ticketee/current/public
     <Directory /somewhere/public>
        AllowOverride all
        Options -MultiViews
     </Directory>
  </VirtualHost>
</pre>

We've changed the +DocumentRoot+ of this +VirtualHost+ to point to the +current/public+ directory of our application's deployment. Apache will serve all requests that match to files in this directory and then will hand-off requests it can't resolve to a file to Passenger, which will spool up an instance of our application and then serve the request.

We need to tell Apache to reload this configuration and we can do this by running this command:

<pre>
  sudo /etc/init.d/apache2 reload
</pre>

That's all there is to getting our application running with Apache. Now when we make a request to our server in our browser, such as +http://our-server+, Apache will receive this request and then Passenger will start up our application. This process usually takes a couple of seconds (depending on the size of the application, bigger applications will take a longer time than smaller applications), but once the application is running it will be serving requests as quick as it can.

h4. nginx

nginx (pronounced "engine x") is an alternative Webserver to Apache. While it's not used in the mainstream as much as Apache, it's still a robust and well-worth web server, with many people in the Ruby community favouring it over Apache due to its faster response times for static content and other things.

h5. Installation & Configuration

The +passenger+ gem comes with the +passenger-install-nginx-module+ which actually does more than what it says on the box. Nginx doesn't support reloadable modules like other webservers (such as Apache) and needs to be recompiled every time a new module is added. If we had nginx installed already, this command would prompt us to either set up a new version of nginx or customize our existing nginx installation by re-compiling it.

Because we don't have nginx installed already, we'll get this command to take care of compiling and installing nginx for us. This command will need to install nginx in system paths on our system and so we need to run this command with +sudo+. Additionally, we'll need to run the initial environment setup for a user's login on this system so that it runs the RVM startup script for the +root+ user, thereby making the +passenger-install-nginx-module+ command available.

The command that we'll run is this:

<pre>
  sudo -i passenger-install-nginx-module
</pre>

When prompted to, we want to "download, compile and install" nginx which is the first option. Type "1" into the prompt and hit enter to get this command to do it for us. This command will then compile and install nginx, outputting each step of the way. 

What we care about is when it stops, it will output this:

[Screenshot nginx passenger http instructions]

It even tells us what to edit ("probably +/opt/nginx/conf/nginx.conf+"). Genius! If we open this file now with +nano /opt/nginx/conf/nginx.conf+ we'll see at the top of the +http+ block... oh! What it tells us to put there is already there. That's some smart thinking!

So there we don't need to anything, which is always a good thing. Doing nothing helps us free up time do to more things including instances of potentially doing nothing. Let's press enter again to get the next set of instructions. They are:

[passenger-nginx-deploy.png]

This are the instructions for how we can tell nginx to run our application. To put these into our nginx configuration, let's run +nano /opt/nginx/conf/nginx.conf+ again. Inside this file there's already a +server+ block underneath the +http+ block, which we can delete but take care in doing so that we don't delete too much.

In its place we will put the following:

<pre>
server {
   listen 80;
   server_name ourserver;
   root /home/deploy/apps/ticketee/current/public;
   passenger_enabled on;
}
</pre>

To start this server which we can do by running the +nginx+ binary itself as +root+.

<pre>
  sudo /opt/nginx/sbin/nginx
</pre>

Usually when we start a background process such as a server, we use what's called an "init script". These scripts are important and are used for setting up services to run when the server boots. The best example of this is back near the beginning of this guide when we used one to restart our SSH server, using this command:

<pre>
  sudo /etc/init.d/ssh restart
</pre>

These scripts often take the +start+, +stop+ and +restart+ arguments, but can take others as well. When our server reboots, nginx, unfortunately, will not.

<pre>
  sudo /etc/init.d/nginx/start
</pre>

To make sure that this server is working as expected we can make a request to http://our-server. Then we should see this page:

[TODO: Show default nginx page]

With nginx now installed we can install the Passenger module that comes with the Passenger gem and then configure nginx to serve requests using that. 